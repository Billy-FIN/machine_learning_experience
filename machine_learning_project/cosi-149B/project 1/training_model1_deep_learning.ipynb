{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bf4e1034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[43.,  3., 33.,  ...,  0.,  0.,  0.],\n",
       "        [49.,  4., 33.,  ...,  0.,  0.,  0.],\n",
       "        [29.,  1., 36.,  ...,  0.,  0.,  0.],\n",
       "        ...,\n",
       "        [46.,  3., 41.,  ...,  0.,  0.,  1.],\n",
       "        [49.,  4., 38.,  ...,  0.,  0.,  0.],\n",
       "        [41.,  2., 33.,  ...,  0.,  0.,  1.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this model was my first attampt at this project\n",
    "# not so ideal, and has some unreasonable process\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# pre-process the data: converting categorical data to numerical data\n",
    "data_path = \"./data_training.csv\"\n",
    "data_pd = pd.read_csv(data_path)\n",
    "categorical_data = data_pd.select_dtypes(include=[\"object\"])\n",
    "numerical_data = data_pd.select_dtypes(exclude=['object']).to_numpy()\n",
    "categorical_data_onehot = pd.get_dummies(categorical_data).to_numpy()   # transfer to one-hot\n",
    "merged_data = np.concatenate((numerical_data, categorical_data_onehot), axis=1)    # merge two data forms\n",
    "data = torch.from_numpy(merged_data).to(torch.float32)   # convert the data to tensor\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6bbdc2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device cuda.\n"
     ]
    }
   ],
   "source": [
    "device = (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
    "print(f\"Training on device {device}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "244d2a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1.,  ..., 1., 1., 1.]),\n",
       " torch.Size([8101]),\n",
       " tensor(1.),\n",
       " tensor(2.))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the label\n",
    "ground_truth = data[:,14]\n",
    "ground_truth, ground_truth.shape, ground_truth.min(), ground_truth.max() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a30dce1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8101, 37])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delete the label column in the training data\n",
    "data = torch.cat((data[:, :14], data[:, 14 + 1:]), dim=1)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "850d973d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         ...,\n",
       "         [1., 0.],\n",
       "         [1., 0.],\n",
       "         [1., 0.]]),\n",
       " torch.Size([8101, 2]),\n",
       " tensor([0., 1.]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# deal with the ground truth, making the data in one-hot form\n",
    "ground_truth = ground_truth.long()\n",
    "truth_onehot = torch.zeros(ground_truth.shape[0], 3)\n",
    "truth_onehot.scatter_(1, ground_truth.unsqueeze(1), 1.0)\n",
    "truth_onehot = truth_onehot[:, 1:]\n",
    "truth_onehot,truth_onehot.shape,truth_onehot[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "878cfea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6481, 37]),\n",
       " torch.Size([6481, 2]),\n",
       " torch.Size([1620, 37]),\n",
       " torch.Size([1620, 2]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross validation prepration\n",
    "n_samples = data.shape[0]\n",
    "n_val = int(0.2 * n_samples)\n",
    "shuffled_indices = torch.randperm(n_samples)    # randomly choose some indices\n",
    "train_indices = shuffled_indices[:-n_val]    # 80% of those random indices are marked as indices for training\n",
    "val_indices = shuffled_indices[-n_val:]      # 20% of those random indices are marked as indices for validating\n",
    "\n",
    "# split the data set for training and testing\n",
    "train_set_x = data[train_indices].to(device=device)\n",
    "train_set_y = truth_onehot[train_indices].to(device=device)\n",
    "val_set_x = data[val_indices].to(device=device)\n",
    "val_set_y = truth_onehot[val_indices].to(device=device)\n",
    "\n",
    "train_set_x.shape,train_set_y.shape,val_set_x.shape,val_set_y.shape\n",
    "# train_set_x,train_set_y,val_set_x,val_set_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1ca76d14",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training loss 1.1160508394241333, Validation loss 1.1303942203521729\n",
      "Accuracy: 5.19%\n",
      "Epoch 100, Training loss 0.4748108685016632, Validation loss 0.470669150352478\n",
      "Accuracy: 84.26%\n",
      "Epoch 200, Training loss 0.4748108685016632, Validation loss 0.470669150352478\n",
      "Accuracy: 84.26%\n",
      "Epoch 300, Training loss 0.4748108685016632, Validation loss 0.470669150352478\n",
      "Accuracy: 84.26%\n",
      "Epoch 400, Training loss 0.4748108685016632, Validation loss 0.470669150352478\n",
      "Accuracy: 84.26%\n",
      "Epoch 500, Training loss 0.4748108685016632, Validation loss 0.470669150352478\n",
      "Accuracy: 84.26%\n",
      "Epoch 600, Training loss 0.4748108685016632, Validation loss 0.470669150352478\n",
      "Accuracy: 84.26%\n",
      "Epoch 700, Training loss 0.4748108685016632, Validation loss 0.470669150352478\n",
      "Accuracy: 84.26%\n",
      "Epoch 800, Training loss 0.4748108685016632, Validation loss 0.470669150352478\n",
      "Accuracy: 84.26%\n",
      "Epoch 900, Training loss 0.4748108685016632, Validation loss 0.470669150352478\n",
      "Accuracy: 84.26%\n",
      "Epoch 1000, Training loss 0.4748108685016632, Validation loss 0.470669150352478\n",
      "Accuracy: 84.26%\n",
      "Epoch 1100, Training loss 0.4748108685016632, Validation loss 0.470669150352478\n",
      "Accuracy: 84.26%\n",
      "Epoch 1200, Training loss 0.4748108685016632, Validation loss 0.470669150352478\n",
      "Accuracy: 84.26%\n",
      "Epoch 1300, Training loss 0.4748108685016632, Validation loss 0.470669150352478\n",
      "Accuracy: 84.26%\n",
      "Epoch 1400, Training loss 0.4748108685016632, Validation loss 0.470669150352478\n",
      "Accuracy: 84.26%\n",
      "Epoch 1500, Training loss 0.4748108685016632, Validation loss 0.470669150352478\n",
      "Accuracy: 84.26%\n",
      "Epoch 1600, Training loss 0.4748108685016632, Validation loss 0.470669150352478\n",
      "Accuracy: 84.26%\n",
      "Epoch 1700, Training loss 0.4748108685016632, Validation loss 0.470669150352478\n",
      "Accuracy: 84.26%\n",
      "Epoch 1800, Training loss 0.4748108685016632, Validation loss 0.470669150352478\n",
      "Accuracy: 84.26%\n",
      "Epoch 1900, Training loss 0.4748108685016632, Validation loss 0.470669150352478\n",
      "Accuracy: 84.26%\n",
      "Epoch 2000, Training loss 0.4748108685016632, Validation loss 0.470669150352478\n",
      "Accuracy: 84.26%\n",
      "Epoch 2100, Training loss 0.4748108685016632, Validation loss 0.470669150352478\n",
      "Accuracy: 84.26%\n",
      "Epoch 2200, Training loss 0.4748108685016632, Validation loss 0.470669150352478\n",
      "Accuracy: 84.26%\n",
      "Epoch 2300, Training loss 0.4748108685016632, Validation loss 0.470669150352478\n",
      "Accuracy: 84.26%\n",
      "Epoch 2400, Training loss 0.4748108685016632, Validation loss 0.470669150352478\n",
      "Accuracy: 84.26%\n",
      "Epoch 2500, Training loss 0.4748108685016632, Validation loss 0.470669150352478\n",
      "Accuracy: 84.26%\n",
      "Epoch 2600, Training loss 0.4748108685016632, Validation loss 0.470669150352478\n",
      "Accuracy: 84.26%\n",
      "Epoch 2700, Training loss 0.4748108685016632, Validation loss 0.470669150352478\n",
      "Accuracy: 84.26%\n",
      "Epoch 2800, Training loss 0.4748108685016632, Validation loss 0.470669150352478\n",
      "Accuracy: 84.26%\n",
      "Epoch 2900, Training loss 0.4748108685016632, Validation loss 0.470669150352478\n",
      "Accuracy: 84.26%\n",
      "Epoch 3000, Training loss 0.4748108685016632, Validation loss 0.470669150352478\n",
      "Accuracy: 84.26%\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# construct a model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(37, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(1024, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 2),\n",
    "    nn.Softmax(dim=1)\n",
    ")\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)     # use Adam becuase the data set is not normalized\n",
    "\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn,x_train,x_val,y_train,y_val):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        # train and calculate the loss\n",
    "        y_train_pred = model(x_train)\n",
    "        loss_train = loss_fn(y_train_pred, y_train)\n",
    "        y_val_pred = model(x_val)\n",
    "        loss_val = loss_fn(y_val_pred, y_val)\n",
    "        \n",
    "        # Auto_grad\n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch == 1 or epoch % 100 == 0:\n",
    "            print('Epoch {}, Training loss {}, Validation loss {}'.format(\n",
    "                epoch, float(loss_train), float(loss_val)))\n",
    "            correct = 0\n",
    "            i = 0\n",
    "            while(i < 1620):\n",
    "                if((y_val_pred[i] == y_val[i]).all()):    # check the prediction\n",
    "                    correct += 1\n",
    "                i += 1\n",
    "            total = y_val.size(0)\n",
    "            accuracy = correct / total\n",
    "            print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 3000,\n",
    "    optimizer = optimizer,\n",
    "    model = model.to(device=device),\n",
    "    loss_fn = loss_fn,\n",
    "    x_train = train_set_x,\n",
    "    y_train = train_set_y,\n",
    "    x_val = val_set_x,\n",
    "    y_val = val_set_y\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "80a44b8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4b5bba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a557685e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff770a22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
