{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59qfiDHHeyin"
      },
      "source": [
        "# Project 3\n",
        "The prediction of molecular properties is an important task in drug discovery. The molecules' atomic composition and arrangement can already tell us a lot about their biological behavior. Each 2D molecule can be represented as a graph, where the nodes are atoms connected by edges corresponding to chemical bonds. The prediction of molecular properties can be formulized as a graph classification task, and graph neural network is usually applied for making graph-level prediction.\n",
        "\n",
        "In this project, you need develop a model for predicting the toxicity of new molecules. This notebook provides a sample pipeline that establishes a baseline. It is expected that your methods should outperform this baseline. You are strongly encouraged to think about designing more powerful models, finetuning hyperparameters, developing better training strategies, etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTCASsyypP4K"
      },
      "source": [
        "# Install package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1peiPgqo5IX",
        "outputId": "c3004e4c-3abd-49f4-c12c-f85409e8fdac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2023.11.17)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.2.0)\n",
            "Installing collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.4.0\n",
            "Collecting rdkit-pypi\n",
            "  Downloading rdkit_pypi-2022.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.4/29.4 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit-pypi) (1.23.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit-pypi) (9.4.0)\n",
            "Installing collected packages: rdkit-pypi\n",
            "Successfully installed rdkit-pypi-2022.9.5\n"
          ]
        }
      ],
      "source": [
        "# New these two packages\n",
        "!pip install torch_geometric\n",
        "!pip install rdkit-pypi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQLM3rMTpu6r"
      },
      "source": [
        "# Some tutorials.\n",
        "\n",
        "\n",
        "\n",
        "1.   Pytorch geometric package: https://pytorch-geometric.readthedocs.io/en/latest/get_started/introduction.html\n",
        "2.   PyTorch Geometric for Graph-Based Molecular Property Prediction using MoleculeNet benchmark: https://medium.com/@nikopavl4/pytorch-geometric-for-graph-based-molecular-property-prediction-using-moleculenet-benchmark-41e36369d3c6\n",
        "3. Graph neural networks for graph classification. https://colab.research.google.com/drive/1I8a0DfQ3fI7Njc62__mVXUlcAleUclnb?usp=sharing\n",
        "4. Related github repository on molecular property predictions. https://github.com/yifeiwang15/MotifConv/tree/main/MCM_for_molecule_benchmarks\n",
        "\n",
        "\n",
        "## What are node and edge features in a molecule.\n",
        "\n",
        "### Node features:\n",
        "\n",
        "**Atomic number**: Number of protons in the nucleus of an atom. It’s characteristic of a chemical element and determines its place in the periodic table.\n",
        "\n",
        "**Chirality**: A molecule is chiral if it is distinguishable from its mirror image by any combination of rotations, translations, and some conformational changes. Different types of chirality exist depending on the molecule and the arrangement of the atoms.\n",
        "\n",
        "**Degree**: Number of directly-bonded neighbors of the atom.\n",
        "Formal charge: Charge assigned to an atom. It reflects the electron count associated with the atom compared to the isolated neutral atom.\n",
        "\n",
        "**Number of H**: Total number of hydrogen atoms on the atom.\n",
        "Number of radical e: Number of unpaired electrons of the atom.\n",
        "\n",
        "**Hybridization**: Atom’s hybridization.\n",
        "\n",
        "**Is aromatic**: Whether it is included in a cyclic structure with pi bonds. This type of structure tends to be very stable in comparison with other geometric arrangements of the same atoms.\n",
        "\n",
        "**Is in ring**: Whether it is included in a ring (a simple cycle of atoms and bonds in a molecule).\n",
        "\n",
        "### Edge features:\n",
        "\n",
        "**Bond type:**: Whether the bond is single, double, triple, or aromatic.\n",
        "\n",
        "**Stereo Type:** Stereo configuration of the bond.\n",
        "\n",
        "**Is conjugated**: Whether or not the bond is considered to be conjugated.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0054Ib-4Vfaj"
      },
      "source": [
        "# Dataset preparation and train-valid splitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "atIc86zFnj0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97305820-8580-4b4e-e77b-038f583ef466"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch_geometric\n",
        "import numpy as np\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.data import DataLoader\n",
        "from torch_geometric.datasets import MoleculeNet\n",
        "import pickle\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"GPU is available\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available, using CPU instead\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZ5wSHOFrDz1",
        "outputId": "c2469989-42a0-4d26-ec07-0f76859391e4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqVa56ajntas",
        "outputId": "e99ef06e-799a-4f73-f876-49e737d4fccf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of training set: 6264\n",
            "Size of validation set: 783\n",
            "Size of test set: 784\n"
          ]
        }
      ],
      "source": [
        "# Load datasets. The training and validation sets contain both molecules and their property labels. The test set only contain molecules.\n",
        "# There are 12 property tasks for prediction. Some properties labels are missing (i.e., nan). You can ignore them.\n",
        "train_dataset = torch.load(\"/content/drive/MyDrive/2023 Fall/cosi149 - project 3/project 3/train_data.pt/train_data.pt\")\n",
        "valid_dataset = torch.load(\"/content/drive/MyDrive/2023 Fall/cosi149 - project 3/project 3/valid_data.pt/valid_data.pt\")\n",
        "test_dataset = torch.load(\"/content/drive/MyDrive/2023 Fall/cosi149 - project 3/project 3/test_data.pt/test_data.pt\")\n",
        "\n",
        "# for g in train_dataset:\n",
        "#   g.x = g.x.to(torch.float32)\n",
        "# for g in test_dataset:\n",
        "#   g.x = g.x.to(torch.float32)\n",
        "# for tensor in valid_dataset:\n",
        "#   g.x = g.x.to(torch.float32)\n",
        "\n",
        "print(f'Size of training set: {len(train_dataset)}')\n",
        "print(f'Size of validation set: {len(valid_dataset)}')\n",
        "print(f'Size of test set: {len(test_dataset)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQRRylPsVYKn",
        "outputId": "debae489-868a-4c33-8167-af9922885679"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(x=[20, 9], edge_index=[2, 38], edge_attr=[38, 3], y=[1, 12], smiles='CC(C)(C)OOC(C)(C)CCC(C)(C)OOC(C)(C)C')\n",
            "Get node feature matrix:\n",
            "tensor([[6, 0, 4, 5, 3, 0, 4, 0, 0],\n",
            "        [6, 0, 4, 5, 0, 0, 4, 0, 0],\n",
            "        [6, 0, 4, 5, 3, 0, 4, 0, 0],\n",
            "        [6, 0, 4, 5, 3, 0, 4, 0, 0],\n",
            "        [8, 0, 2, 5, 0, 0, 4, 0, 0],\n",
            "        [8, 0, 2, 5, 0, 0, 4, 0, 0],\n",
            "        [6, 0, 4, 5, 0, 0, 4, 0, 0],\n",
            "        [6, 0, 4, 5, 3, 0, 4, 0, 0],\n",
            "        [6, 0, 4, 5, 3, 0, 4, 0, 0],\n",
            "        [6, 0, 4, 5, 2, 0, 4, 0, 0],\n",
            "        [6, 0, 4, 5, 2, 0, 4, 0, 0],\n",
            "        [6, 0, 4, 5, 0, 0, 4, 0, 0],\n",
            "        [6, 0, 4, 5, 3, 0, 4, 0, 0],\n",
            "        [6, 0, 4, 5, 3, 0, 4, 0, 0],\n",
            "        [8, 0, 2, 5, 0, 0, 4, 0, 0],\n",
            "        [8, 0, 2, 5, 0, 0, 4, 0, 0],\n",
            "        [6, 0, 4, 5, 0, 0, 4, 0, 0],\n",
            "        [6, 0, 4, 5, 3, 0, 4, 0, 0],\n",
            "        [6, 0, 4, 5, 3, 0, 4, 0, 0],\n",
            "        [6, 0, 4, 5, 3, 0, 4, 0, 0]])\n",
            "torch.Size([20, 9])\n",
            "Get edge index matrix:\n",
            "tensor([[ 0,  1,  1,  1,  1,  2,  3,  4,  4,  5,  5,  6,  6,  6,  6,  7,  8,  9,\n",
            "          9, 10, 10, 11, 11, 11, 11, 12, 13, 14, 14, 15, 15, 16, 16, 16, 16, 17,\n",
            "         18, 19],\n",
            "        [ 1,  0,  2,  3,  4,  1,  1,  1,  5,  4,  6,  5,  7,  8,  9,  6,  6,  6,\n",
            "         10,  9, 11, 10, 12, 13, 14, 11, 11, 11, 15, 14, 16, 15, 17, 18, 19, 16,\n",
            "         16, 16]])\n",
            "torch.Size([2, 38])\n",
            "Get edge attribute matrix:\n",
            "tensor([[1, 0, 0],\n",
            "        [1, 0, 0],\n",
            "        [1, 0, 0],\n",
            "        [1, 0, 0],\n",
            "        [1, 0, 0],\n",
            "        [1, 0, 0],\n",
            "        [1, 0, 0],\n",
            "        [1, 0, 0],\n",
            "        [1, 0, 0],\n",
            "        [1, 0, 0],\n",
            "        [1, 0, 0],\n",
            "        [1, 0, 0],\n",
            "        [1, 0, 0],\n",
            "        [1, 0, 0],\n",
            "        [1, 0, 0],\n",
            "        [1, 0, 0],\n",
            "        [1, 0, 0],\n",
            "        [1, 0, 0],\n",
            "        [1, 0, 0],\n",
            "        [1, 0, 0],\n",
            "        [1, 0, 0],\n",
            "        [1, 0, 0],\n",
            "        [1, 0, 0],\n",
            "        [1, 0, 0],\n",
            "        [1, 0, 0],\n",
            "        [1, 0, 0],\n",
            "        [1, 0, 0],\n",
            "        [1, 0, 0],\n",
            "        [1, 0, 0],\n",
            "        [1, 0, 0],\n",
            "        [1, 0, 0],\n",
            "        [1, 0, 0],\n",
            "        [1, 0, 0],\n",
            "        [1, 0, 0],\n",
            "        [1, 0, 0],\n",
            "        [1, 0, 0],\n",
            "        [1, 0, 0],\n",
            "        [1, 0, 0]])\n",
            "torch.Size([38, 3])\n",
            "Get molecular property labels:\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., nan, 0., 0., 0., 0.]])\n",
            "torch.Size([1, 12])\n"
          ]
        }
      ],
      "source": [
        "# one graph example\n",
        "g = train_dataset[1]\n",
        "print(g)\n",
        "\n",
        "print(\"Get node feature matrix:\")\n",
        "print(g.x)\n",
        "print(g.x.shape) # (num_of_nodes, num_of_node_features)\n",
        "\n",
        "print(\"Get edge index matrix:\")\n",
        "print(g.edge_index)\n",
        "print(g.edge_index.shape) # (2, num_of_edges)\n",
        "\n",
        "print(\"Get edge attribute matrix:\")\n",
        "print(g.edge_attr)\n",
        "print(g.edge_attr.shape) # (num_of_edges, num_of_edge_features)\n",
        "\n",
        "print(\"Get molecular property labels:\")\n",
        "print(g.y)\n",
        "print(g.y.shape) # (1, 12)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cilgcBXdCNS3"
      },
      "source": [
        "As we can observe, we have 11 nodes (rows) and each node has 9 features (columns). However, the features provided by Moleculenet are discrete and of type long, so we need to convert them first to continuous embeddings in order to feed them in any ML model.\n",
        "\n",
        "For example, the first column indicates the atomic number of a node, where 1 represents Hydrogen, 6 represents Carbon, 8 for Oxygen, according to periodic table of elements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZLIUrqobxY3",
        "outputId": "caddc742-0533-4113-e61e-75ee609b414d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        }
      ],
      "source": [
        "# Example of preparing data loaders.\n",
        "# You can use any batch size and see what happens in model performance.\n",
        "\n",
        "from torch_geometric.data import DataLoader\n",
        "\n",
        "batch_size=32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mc2_Mytlhn5P"
      },
      "source": [
        "# Visualization of molecules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "BNoZJPN0ic5S",
        "outputId": "a22e5151-22d8-4987-fae2-f32d2b8b5144"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<rdkit.Chem.rdchem.Mol at 0x7fc5161902e0>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# visualize one 2D molecule.\n",
        "from rdkit import Chem\n",
        "Chem.MolFromSmiles(g.smiles)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3O_MZj_TjJ7"
      },
      "source": [
        "# Build model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0Agk424bTnmZ"
      },
      "outputs": [],
      "source": [
        "# Atom encoder\n",
        "\n",
        "class AtomEncoder(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super(AtomEncoder, self).__init__()\n",
        "\n",
        "        self.embeddings = torch.nn.ModuleList()\n",
        "\n",
        "        for i in range(9):\n",
        "            self.embeddings.append(torch.nn.Embedding(100, hidden_channels))\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for embedding in self.embeddings:\n",
        "            embedding.reset_parameters()\n",
        "\n",
        "    def forward(self, x):\n",
        "        if x.dim() == 1:\n",
        "            x = x.unsqueeze(1)\n",
        "\n",
        "        out = 0\n",
        "        for i in range(x.size(1)):\n",
        "            out += self.embeddings[i](x[:, i])\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem, RDKFingerprint, MACCSkeys\n",
        "\n",
        "\n",
        "def generate_fingerprints(smiles_list, fingerprint_size=1024):\n",
        "        fingerprints = []\n",
        "        for smiles in smiles_list:\n",
        "            molecule = Chem.MolFromSmiles(smiles)\n",
        "            # molecule = Chem.RemoveHs(molecule)\n",
        "            if molecule is not None:  # Check if the molecule conversion is successful\n",
        "                fp = AllChem.GetMorganFingerprintAsBitVect(molecule, radius=2, nBits=fingerprint_size)\n",
        "                # fp = MACCSkeys.GenMACCSKeys(molecule)\n",
        "                # fp = RDKFingerprint(molecule)\n",
        "                fingerprints.append(fp)\n",
        "            else:\n",
        "                fingerprints.append(None)  # Handle cases where SMILES conversion fails\n",
        "        return fingerprints"
      ],
      "metadata": {
        "id": "RiUvjER_1yn7"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# multiheads GAT\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GATConv, global_mean_pool as gap\n",
        "from torch.nn import Linear\n",
        "\n",
        "class GAT(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels, num_node_features, num_classes, num_heads=4):\n",
        "        super(GAT, self).__init__()\n",
        "        torch.manual_seed(42)\n",
        "        self.emb = AtomEncoder(num_node_features)\n",
        "\n",
        "        # Adjusted to include multi-head attention\n",
        "        self.conv1 = GATConv(num_node_features, hidden_channels, heads=num_heads, concat=True)\n",
        "        self.conv2 = GATConv(hidden_channels * num_heads, hidden_channels, heads=num_heads, concat=True)\n",
        "        self.conv3 = GATConv(hidden_channels * num_heads, hidden_channels, heads=num_heads, concat=False)  # Concat=False for the last layer\n",
        "\n",
        "        self.fingerprint_lin = Linear(1024, hidden_channels)\n",
        "        self.lin = Linear(hidden_channels*2, num_classes)\n",
        "\n",
        "    def forward(self, batch):\n",
        "        x, edge_index, edge_attr, batch_size, batch_smiles = batch.x, batch.edge_index, batch.edge_attr, batch.batch, batch.smiles\n",
        "        x = self.emb(x)\n",
        "\n",
        "        # 1. Obtain node embeddings using multi-head GATConv layers\n",
        "        x = F.relu(self.conv1(x, edge_index, edge_attr))\n",
        "        x = F.relu(self.conv2(x, edge_index, edge_attr))\n",
        "        x = self.conv3(x, edge_index, edge_attr)  # No ReLU after the last GATConv layer\n",
        "\n",
        "        # 2. Readout layer\n",
        "        x = gap(x, batch_size)  # [batch_size, hidden_channels]\n",
        "\n",
        "        batch_fingerprints = generate_fingerprints(batch_smiles)\n",
        "        batch_fingerprints = torch.tensor(batch_fingerprints, dtype=torch.float).to(x.device)  # Use the same device as x\n",
        "        fingerprint = self.fingerprint_lin(batch_fingerprints).relu()\n",
        "        x = torch.cat([x, fingerprint], dim=1)  # Concatenate along the feature dimension\n",
        "\n",
        "        # 3. Apply a final classifier\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.lin(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "7HvmXTYIJ8MD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GAT\n",
        "\n",
        "from torch_geometric.nn import GATConv, global_mean_pool as gap\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Linear, LSTM\n",
        "\n",
        "class GAT(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels, num_node_features, num_classes):\n",
        "        super(GAT, self).__init__()\n",
        "        torch.manual_seed(42)\n",
        "        self.emb = AtomEncoder(num_node_features)\n",
        "        self.conv1 = GATConv(num_node_features, hidden_channels)\n",
        "        self.conv2 = GATConv(hidden_channels, hidden_channels)\n",
        "        self.conv3 = GATConv(hidden_channels, hidden_channels)\n",
        "        self.lstm = LSTM(input_size=hidden_channels, hidden_size=32, num_layers=2, batch_first=True)\n",
        "        self.fingerprint_lin = Linear(1024, hidden_channels)\n",
        "        self.lin = Linear(hidden_channels * 2, num_classes)\n",
        "\n",
        "    def forward(self, batch):\n",
        "        x, edge_index, edge_attr, batch_size, batch_smiles = batch.x, batch.edge_index, batch.edge_attr, batch.batch, batch.smiles\n",
        "        x = self.emb(x)\n",
        "\n",
        "        # 1. Obtain node embeddings using GATConv layers\n",
        "        x = F.relu(self.conv1(x, edge_index, edge_attr))\n",
        "        x = F.relu(self.conv2(x, edge_index, edge_attr))\n",
        "        x = self.conv3(x, edge_index, edge_attr)\n",
        "\n",
        "\n",
        "        x, _ = self.lstm(x.view(batch_size, -1, x.size(1)))  # Reshape x for LSTM\n",
        "\n",
        "        # 2. Readout layer\n",
        "        x = gap(x, batch_size)  # [batch_size, hidden_channels]\n",
        "\n",
        "        batch_fingerprints = generate_fingerprints(batch_smiles)\n",
        "        batch_fingerprints = torch.tensor(batch_fingerprints, dtype=torch.float).to('cpu')\n",
        "        fingerprint = self.fingerprint_lin(batch_fingerprints).relu()\n",
        "        x = torch.cat([x, fingerprint], dim=1).to('cpu')\n",
        "\n",
        "\n",
        "\n",
        "        # 3. Apply a final classifier\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.lin(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "P1iulDciAnJ3"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fingerprint + GCN\n",
        "\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.nn import global_mean_pool as gap\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Linear\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels, num_node_features, num_classes, fingerprint_dim=167):\n",
        "        super(GCN, self).__init__()\n",
        "        torch.manual_seed(42)\n",
        "        self.emb = AtomEncoder(hidden_channels=32)\n",
        "        self.conv1 = GCNConv(hidden_channels,hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.fingerprint_lin = Linear(fingerprint_dim, hidden_channels)\n",
        "        self.lin = Linear(hidden_channels * 2, num_classes)\n",
        "\n",
        "    def forward(self, batch):\n",
        "        x , edge_index, batch_size, batch_smiles = batch.x, batch.edge_index, batch.batch, batch.smiles\n",
        "        x = self.emb(x)\n",
        "        # 1. Obtain node embeddings\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv3(x, edge_index)\n",
        "\n",
        "        # 2. Readout layer\n",
        "        x = gap(x, batch_size)  # [batch_size, hidden_channels]\n",
        "        # 3. Generate fingerprints and take them into consideration\n",
        "        batch_fingerprints = generate_fingerprints(batch_smiles)\n",
        "        batch_fingerprints = torch.tensor(batch_fingerprints, dtype=torch.float).to('cuda')\n",
        "        fingerprint = self.fingerprint_lin(batch_fingerprints).relu()\n",
        "        x = torch.cat([x, fingerprint], dim=1).to('cuda')\n",
        "\n",
        "        # 3. Apply a final classifier\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.lin(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "xtxswdSvxesX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# graph embedding + gcn\n",
        "import pandas as pd\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.nn import global_mean_pool as gap\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Linear\n",
        "import networkx as nx\n",
        "from karateclub import Graph2Vec\n",
        "\n",
        "def generate_g_embedding(smiles):\n",
        "    smiles = pd.Series(smiles)\n",
        "    mol = smiles.apply(lambda x: Chem.MolFromSmiles(x))\n",
        "    graphs = mol.apply(lambda x: mol_to_nx(x))\n",
        "    graph2vec = Graph2Vec()\n",
        "    graph2vec.fit(graphs)\n",
        "    embeddings = graph2vec.get_embedding()\n",
        "\n",
        "def mol_to_nx(mol):\n",
        "    G = nx.Graph()\n",
        "\n",
        "    for atom in mol.GetAtoms():\n",
        "        G.add_node(atom.GetIdx(),\n",
        "                   atomic_num=atom.GetAtomicNum(),\n",
        "                   is_aromatic=atom.GetIsAromatic(),\n",
        "                   atom_symbol=atom.GetSymbol())\n",
        "\n",
        "    for bond in mol.GetBonds():\n",
        "        G.add_edge(bond.GetBeginAtomIdx(),\n",
        "                   bond.GetEndAtomIdx(),\n",
        "                   bond_type=bond.GetBondType())\n",
        "\n",
        "    return G\n",
        "\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels, num_node_features, num_classes):\n",
        "        super(GCN, self).__init__()\n",
        "        torch.manual_seed(42)\n",
        "        self.conv1 = GCNConv(hidden_channels,hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.lin = Linear(hidden_channels, num_classes)\n",
        "\n",
        "    def forward(self, batch):\n",
        "        x , edge_index, batch_size, batch_smiles = batch.x, batch.edge_index, batch.batch, batch.smiles\n",
        "        x = generate_g_embedding(batch_smiles)\n",
        "        # 1. Obtain node embeddings\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv3(x, edge_index)\n",
        "\n",
        "        # 2. Readout layer\n",
        "        x = gap(x, batch_size)  # [batch_size, hidden_channels]\n",
        "        # 3. Apply a final classifier\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.lin(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "nCLtYJ6pQspg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# base model + fingerprint\n",
        "\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.nn import global_mean_pool as gap\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Linear\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels, num_node_features, num_classes):\n",
        "        super(GCN, self).__init__()\n",
        "        torch.manual_seed(42)\n",
        "        self.emb = AtomEncoder(hidden_channels=32)\n",
        "        self.conv1 = GCNConv(hidden_channels,64)\n",
        "        self.conv2 = GCNConv(64, 128)\n",
        "        self.conv3 = GCNConv(128, 32)\n",
        "        self.lin = Linear(hidden_channels, num_classes)\n",
        "\n",
        "    def forward(self, batch):\n",
        "        x , edge_index, batch_size = batch.x, batch.edge_index, batch.batch\n",
        "        x = self.emb(x)\n",
        "        # 1. Obtain node embeddings\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv3(x, edge_index)\n",
        "\n",
        "        # 2. Readout layer\n",
        "        x = gap(x, batch_size)  # [batch_size, hidden_channels]\n",
        "        # 3. Apply a final classifier\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.lin(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "yeOJwUo8aOfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# base model\n",
        "# A simple graph neural network model\n",
        "\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.nn import global_mean_pool as gap\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Linear\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels, num_node_features, num_classes):\n",
        "        super(GCN, self).__init__()\n",
        "        torch.manual_seed(42)\n",
        "        self.emb = AtomEncoder(hidden_channels=32)\n",
        "        self.conv1 = GCNConv(hidden_channels,hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
        "        self.lin = Linear(hidden_channels, num_classes)\n",
        "\n",
        "    def forward(self, batch):\n",
        "        x , edge_index, batch_size = batch.x, batch.edge_index, batch.batch\n",
        "        x = self.emb(x)\n",
        "        # 1. Obtain node embeddings\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = x.relu()\n",
        "        x = self.conv3(x, edge_index)\n",
        "\n",
        "        # 2. Readout layer\n",
        "        x = gap(x, batch_size)  # [batch_size, hidden_channels]\n",
        "        # 3. Apply a final classifier\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.lin(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "1hJlD8vM0IVP"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import Tensor\n",
        "from torch.nn import GRUCell, Linear, Parameter, BatchNorm1d\n",
        "\n",
        "from torch_geometric.nn import GATConv, MessagePassing, global_add_pool\n",
        "from torch_geometric.nn.inits import glorot, zeros\n",
        "from torch_geometric.typing import Adj, OptTensor\n",
        "from torch_geometric.utils import softmax\n",
        "\n",
        "\n",
        "class GATEConv(MessagePassing):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: int,\n",
        "        out_channels: int,\n",
        "        edge_dim: int,\n",
        "        dropout: float = 0.0,\n",
        "    ):\n",
        "        super().__init__(aggr='add', node_dim=0)\n",
        "\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.att_l = Parameter(torch.empty(1, out_channels))\n",
        "        self.att_r = Parameter(torch.empty(1, in_channels))\n",
        "\n",
        "        self.lin1 = Linear(in_channels + edge_dim, out_channels, False)\n",
        "        self.lin2 = Linear(out_channels, out_channels, False)\n",
        "\n",
        "        self.bias = Parameter(torch.empty(out_channels))\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        glorot(self.att_l)\n",
        "        glorot(self.att_r)\n",
        "        glorot(self.lin1.weight)\n",
        "        glorot(self.lin2.weight)\n",
        "        zeros(self.bias)\n",
        "\n",
        "    def forward(self, x: Tensor, edge_index: Adj, edge_attr: Tensor) -> Tensor:\n",
        "        # edge_updater_type: (x: Tensor, edge_attr: Tensor)\n",
        "        alpha = self.edge_updater(edge_index, x=x, edge_attr=edge_attr)\n",
        "\n",
        "        # propagate_type: (x: Tensor, alpha: Tensor)\n",
        "        out = self.propagate(edge_index, x=x, alpha=alpha, size=None)\n",
        "        out = out + self.bias\n",
        "        return out\n",
        "\n",
        "    def edge_update(self, x_j: Tensor, x_i: Tensor, edge_attr: Tensor,\n",
        "                    index: Tensor, ptr: OptTensor,\n",
        "                    size_i: Optional[int]) -> Tensor:\n",
        "        x_j = F.leaky_relu_(self.lin1(torch.cat([x_j, edge_attr], dim=-1)))\n",
        "        alpha_j = (x_j @ self.att_l.t()).squeeze(-1)\n",
        "        alpha_i = (x_i @ self.att_r.t()).squeeze(-1)\n",
        "        alpha = alpha_j + alpha_i\n",
        "        alpha = F.leaky_relu_(alpha)\n",
        "        alpha = softmax(alpha, index, ptr, size_i)\n",
        "        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n",
        "        return alpha\n",
        "\n",
        "    def message(self, x_j: Tensor, alpha: Tensor) -> Tensor:\n",
        "        return self.lin2(x_j) * alpha.unsqueeze(-1)\n",
        "\n",
        "\n",
        "class AttentiveFP(torch.nn.Module):\n",
        "    r\"\"\"The Attentive FP model for molecular representation learning from the\n",
        "    `\"Pushing the Boundaries of Molecular Representation for Drug Discovery\n",
        "    with the Graph Attention Mechanism\"\n",
        "    <https://pubs.acs.org/doi/10.1021/acs.jmedchem.9b00959>`_ paper, based on\n",
        "    graph attention mechanisms.\n",
        "\n",
        "    Args:\n",
        "        in_channels (int): Size of each input sample.\n",
        "        hidden_channels (int): Hidden node feature dimensionality.\n",
        "        out_channels (int): Size of each output sample.\n",
        "        edge_dim (int): Edge feature dimensionality.\n",
        "        num_layers (int): Number of GNN layers.\n",
        "        num_timesteps (int): Number of iterative refinement steps for global\n",
        "            readout.\n",
        "        dropout (float, optional): Dropout probability. (default: :obj:`0.0`)\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_channels: int,\n",
        "        hidden_channels: int,\n",
        "        out_channels: int,\n",
        "        edge_dim: int,\n",
        "        num_layers: int,\n",
        "        num_timesteps: int,\n",
        "        dropout: float = 0.0,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.bn1 = BatchNorm1d(hidden_channels)\n",
        "        self.in_channels = in_channels\n",
        "        self.hidden_channels = hidden_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.edge_dim = edge_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.num_timesteps = num_timesteps\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.lin1 = Linear(in_channels, hidden_channels)\n",
        "\n",
        "        self.gate_conv = GATEConv(hidden_channels, hidden_channels, edge_dim,\n",
        "                                  dropout)\n",
        "        self.gru = GRUCell(hidden_channels, hidden_channels)\n",
        "\n",
        "        self.atom_convs = torch.nn.ModuleList()\n",
        "        self.atom_grus = torch.nn.ModuleList()\n",
        "        for _ in range(num_layers - 1):\n",
        "            conv = GATConv(hidden_channels, hidden_channels, dropout=dropout,\n",
        "                           add_self_loops=False, negative_slope=0.01)\n",
        "            self.atom_convs.append(conv)\n",
        "            self.atom_grus.append(GRUCell(hidden_channels, hidden_channels))\n",
        "\n",
        "        self.mol_conv = GATConv(hidden_channels, hidden_channels,\n",
        "                                dropout=dropout, add_self_loops=False,\n",
        "                                negative_slope=0.01)\n",
        "        self.mol_conv.explain = False  # Cannot explain global pooling.\n",
        "        self.mol_gru = GRUCell(hidden_channels, hidden_channels)\n",
        "\n",
        "        self.lin2 = Linear(hidden_channels, out_channels)\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        r\"\"\"Resets all learnable parameters of the module.\"\"\"\n",
        "        self.lin1.reset_parameters()\n",
        "        self.gate_conv.reset_parameters()\n",
        "        self.gru.reset_parameters()\n",
        "        for conv, gru in zip(self.atom_convs, self.atom_grus):\n",
        "            conv.reset_parameters()\n",
        "            gru.reset_parameters()\n",
        "        self.mol_conv.reset_parameters()\n",
        "        self.mol_gru.reset_parameters()\n",
        "        self.lin2.reset_parameters()\n",
        "\n",
        "    def forward(self, x: Tensor, edge_index: Tensor, edge_attr: Tensor,\n",
        "                batch: Tensor) -> Tensor:\n",
        "        \"\"\"\"\"\"  # noqa: D419\n",
        "        # Atom Embedding:\n",
        "        x = F.leaky_relu_(self.lin1(x))\n",
        "        x = self.bn1(x)\n",
        "\n",
        "        h = F.elu_(self.gate_conv(x, edge_index, edge_attr))\n",
        "        h = F.dropout(h, p=self.dropout, training=self.training)\n",
        "        x = self.gru(h, x).relu_()\n",
        "\n",
        "        for conv, gru in zip(self.atom_convs, self.atom_grus):\n",
        "            h = F.elu_(conv(x, edge_index))\n",
        "            h = F.dropout(h, p=self.dropout, training=self.training)\n",
        "            x = gru(h, x).relu_()\n",
        "\n",
        "        # Molecule Embedding:\n",
        "        row = torch.arange(batch.size(0), device=batch.device)\n",
        "        edge_index = torch.stack([row, batch], dim=0)\n",
        "\n",
        "        out = global_add_pool(x, batch).relu_()\n",
        "        for t in range(self.num_timesteps):\n",
        "            h = F.elu_(self.mol_conv((x, out), edge_index))\n",
        "            h = F.dropout(h, p=self.dropout, training=self.training)\n",
        "            out = self.mol_gru(h, out).relu_()\n",
        "\n",
        "        # Predictor:\n",
        "        out = F.dropout(out, p=self.dropout, training=self.training)\n",
        "        return self.lin2(out)\n",
        "\n",
        "    def jittable(self) -> 'AttentiveFP':\n",
        "        self.gate_conv = self.gate_conv.jittable()\n",
        "        self.atom_convs = torch.nn.ModuleList(\n",
        "            [conv.jittable() for conv in self.atom_convs])\n",
        "        self.mol_conv = self.mol_conv.jittable()\n",
        "        return self\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return (f'{self.__class__.__name__}('\n",
        "                f'in_channels={self.in_channels}, '\n",
        "                f'hidden_channels={self.hidden_channels}, '\n",
        "                f'out_channels={self.out_channels}, '\n",
        "                f'edge_dim={self.edge_dim}, '\n",
        "                f'num_layers={self.num_layers}, '\n",
        "                f'num_timesteps={self.num_timesteps}'\n",
        "                f')')"
      ],
      "metadata": {
        "id": "xLDrfWjPW0e0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIAfufrpuKAm"
      },
      "source": [
        "# Start training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "vCQE_TIoUw4x"
      },
      "outputs": [],
      "source": [
        "# loss function and optimizer\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "# from torch_geometric.nn import AttentiveFP\n",
        "\n",
        "# model = GCN(32, 9, 12).to(device)\n",
        "# model = GAT(32, 9, 12).to(device)\n",
        "model = AttentiveFP(64,128,12,3,3,3, 0.5).to(device)\n",
        "emb = AtomEncoder(64)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
        "criterion = nn.BCEWithLogitsLoss(reduction = \"none\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "6SL3fUw4VD38"
      },
      "outputs": [],
      "source": [
        "# train and eval function\n",
        "from sklearn.metrics import roc_auc_score\n",
        "def train(model, device, loader, optimizer):\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(loader):\n",
        "        pred = model(emb(batch.x).to(device), batch.edge_index.to(device), batch.edge_attr.to(device), batch.batch.to(device))\n",
        "        batch = batch.to(device)\n",
        "        # pred = model(batch)\n",
        "        y = batch.y.view(pred.shape).to(torch.float64)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        ## ignore nan targets (unlabeled) when computing training loss.\n",
        "        is_labeled = batch.y == batch.y\n",
        "        loss = criterion(pred.to(torch.float32)[is_labeled], batch.y.to(torch.float32)[is_labeled]).mean()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "\n",
        "def eval(model, device, loader):\n",
        "    model.eval()\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    # For every batch in test loader\n",
        "    for batch in loader:\n",
        "\n",
        "        batch = batch.to(device)\n",
        "        if batch.x.shape[0] == 1:\n",
        "            pass\n",
        "        else:\n",
        "            with torch.no_grad():\n",
        "                pred = model(emb(batch.x.to('cpu')).to(device), batch.edge_index.to(device), batch.edge_attr.to(device), batch.batch.to(device))\n",
        "                # pred = model(batch)\n",
        "            y_true.append(batch.y.view(pred.shape))\n",
        "            y_pred.append(pred)\n",
        "\n",
        "    y_true = torch.cat(y_true, dim = 0).cpu().numpy()\n",
        "    y_pred = torch.cat(y_pred, dim = 0).cpu().numpy()\n",
        "\n",
        "    # Compute the ROC - AUC score and store as history\n",
        "    rocauc_list = []\n",
        "\n",
        "    for i in range(y_true.shape[1]):\n",
        "        #AUC is only defined when there is at least one positive data.\n",
        "        if np.sum(y_true[:,i] == 1) > 0 and np.sum(y_true[:,i] == 0) > 0:\n",
        "            # ignore nan values\n",
        "            is_labeled = y_true[:,i] == y_true[:,i]\n",
        "            rocauc_list.append(roc_auc_score(y_true[is_labeled,i], y_pred[is_labeled,i]))\n",
        "\n",
        "    if len(rocauc_list) == 0:\n",
        "        raise RuntimeError('No positively labeled data available. Cannot compute ROC-AUC.')\n",
        "\n",
        "    return {'rocauc': sum(rocauc_list)/len(rocauc_list)}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 946
        },
        "id": "yYM7x48bZugM",
        "outputId": "8f113eae-e296-4d5a-f3ea-5a549f07d0ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training...\n",
            "====epoch 1\n",
            "{'Train': {'rocauc': 0.7580468302443402}, 'Validation': {'rocauc': 0.7225408067193076}}\n",
            "====epoch 2\n",
            "{'Train': {'rocauc': 0.7925747622521814}, 'Validation': {'rocauc': 0.7579771474090657}}\n",
            "====epoch 3\n",
            "{'Train': {'rocauc': 0.8071555642662115}, 'Validation': {'rocauc': 0.7642306137499991}}\n",
            "====epoch 4\n",
            "{'Train': {'rocauc': 0.8170826091967465}, 'Validation': {'rocauc': 0.781178944883595}}\n",
            "====epoch 5\n",
            "{'Train': {'rocauc': 0.8349139994998929}, 'Validation': {'rocauc': 0.7904917158486232}}\n",
            "====epoch 6\n",
            "{'Train': {'rocauc': 0.832617115564222}, 'Validation': {'rocauc': 0.790539201113592}}\n",
            "====epoch 7\n",
            "{'Train': {'rocauc': 0.8378519696881548}, 'Validation': {'rocauc': 0.7897770512755683}}\n",
            "====epoch 8\n",
            "{'Train': {'rocauc': 0.8400412385133839}, 'Validation': {'rocauc': 0.7846630886057966}}\n",
            "====epoch 9\n",
            "{'Train': {'rocauc': 0.84545162751883}, 'Validation': {'rocauc': 0.7890624186784083}}\n",
            "====epoch 10\n",
            "{'Train': {'rocauc': 0.8468598402249919}, 'Validation': {'rocauc': 0.7964542435050604}}\n",
            "====epoch 11\n",
            "{'Train': {'rocauc': 0.8520699321216013}, 'Validation': {'rocauc': 0.7961358311168669}}\n",
            "====epoch 12\n",
            "{'Train': {'rocauc': 0.8514784205770881}, 'Validation': {'rocauc': 0.7933287943655584}}\n",
            "====epoch 13\n",
            "{'Train': {'rocauc': 0.8460330316056655}, 'Validation': {'rocauc': 0.7953622479220073}}\n",
            "====epoch 14\n",
            "{'Train': {'rocauc': 0.8506987188340801}, 'Validation': {'rocauc': 0.7973129337808341}}\n",
            "====epoch 15\n",
            "{'Train': {'rocauc': 0.8528258302013043}, 'Validation': {'rocauc': 0.7828161019645578}}\n",
            "====epoch 16\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-77dcda39b5e7>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# evaluating\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-4a182f8f614f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, loader, optimizer)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_attr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# pred = model(batch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-40640bc93a72>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_attr, batch)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgate_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-40640bc93a72>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_attr)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m# propagate_type: (x: Tensor, alpha: Tensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    453\u001b[0m                         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecomp_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m                 coll_dict = self._collect(self._user_args, edge_index, size,\n\u001b[0m\u001b[1;32m    456\u001b[0m                                           kwargs)\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36m_collect\u001b[0;34m(self, args, edge_index, size, kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'_i'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_j'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m                 \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'_j'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Training\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "print(\"Start training...\")\n",
        "\n",
        "for epoch in range(20):\n",
        "    print(\"====epoch \" + str(epoch+1))\n",
        "\n",
        "    # training\n",
        "    train(model, device, train_loader, optimizer)\n",
        "\n",
        "    # evaluating\n",
        "    train_acc = eval(model, device, train_loader)\n",
        "    val_acc = eval(model, device, val_loader)\n",
        "    print({'Train': train_acc, 'Validation': val_acc})\n",
        "\n",
        "    if val_acc['rocauc'] >= 0.8:\n",
        "        break\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), '/content/drive/MyDrive/attentiveFP_1.pt')"
      ],
      "metadata": {
        "id": "8Oz23d4uh6mb"
      },
      "execution_count": 231,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}